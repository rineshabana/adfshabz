{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "shabzadfdemo"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/DataSetSqlTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "SqlServerOnPremise",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "tbl_Employees"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CacheSinkdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "maxaggregate"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 aggregate(MaxSalary = max(toInteger(salary)),",
						"     partitionBy('hash', 1)) ~> maxaggregate",
						"maxaggregate sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ExistsDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "DeptexistSink"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department exists(department == deptid,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['NotExistDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DeptexistSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Flattendataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeesJson",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          name as string,",
						"          skills as string[],",
						"          Address as (state as string, country as string, zipcode as string),",
						"          Contact as (Phone as string, email as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments',",
						"     partitionBy('hash', 1)) ~> Employees",
						"Employees foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills,",
						"          Address,",
						"          Contact",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['FlattenData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/GroupBypowerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "EmployeeDataSet",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tpartitionBy('hash', 1)) ~> EmployeeDataSet",
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared EmployeeDataSet = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoshabz.blob.core.windows.net/adfdemo/input/employee.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"EmployeeDataSet\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"department\"}, {{\"TotalEmp\", each Table.RowCount(_), Int64.Type}}) in #\"Grouped rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LookUpDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees, Department lookup(department == deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['lookup.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/NewBranchdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregateOnDept"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees aggregate(groupBy(department),",
						"     TotalEmployees = count(empid),",
						"     partitionBy('hash', 1)) ~> aggregateOnDept",
						"Employees, Department join(department == deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"aggregateOnDept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['AggregatebyEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          department,",
						"          TotalEmployees",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          deptid,",
						"          depname",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ParameterizeMappingdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     deptName as string",
						"}",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees",
						"Employees filter(department == $deptName) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpParamData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/PivotDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "Employees1DataFlow"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees1DataFlow",
						"Employees1DataFlow pivot(groupBy(department),",
						"     pivotBy(gender),",
						"     {} = count(empid),",
						"     columnNaming: 'Total_$N$VEmployees_',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['pivotdata.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Scehmadataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          salary as string,",
						"          department as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false,",
						"     preferredIntegralType: 'integer') ~> Employees",
						"Employees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['schema.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Selectdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "selectOnEmp"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees select(mapColumn(",
						"          {Emp Name} = name,",
						"          Empid = empid,",
						"          Country = country",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectOnEmp",
						"selectOnEmp sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SelectEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Sortdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sortOnName"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees sort(asc(name, true),",
						"     caseInsensitive: true) ~> sortOnName",
						"sortOnName sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SortEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SplitDF')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "AllEmployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "ITEmployeesSink",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedService_StorageDemo",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "PayrollEmployeeSink"
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "HREmployeeSink"
						}
					],
					"transformations": [
						{
							"name": "ITEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> AllEmployees",
						"AllEmployees split(equals(department,'1'),",
						"     equals(department,'2'),",
						"     equals(department,'3'),",
						"     disjoint: false) ~> ITEmployees@(ITEmployee, PayrollEmployee, HREmployee)",
						"ITEmployees@ITEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ITEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ITEmployeesSink",
						"ITEmployees@PayrollEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['PayrollEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PayrollEmployeeSink",
						"ITEmployees@HREmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['HREmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> HREmployeeSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Surrogatedataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SurrogateKeyDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          department",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Surrogatedata.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/TotalEmpbyDept')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "TotalEmployeebydept"
						}
					],
					"transformations": [
						{
							"name": "aggregateOnDept"
						},
						{
							"name": "joinOnDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees aggregate(groupBy(department),",
						"     TotalEmp = count(empid)) ~> aggregateOnDept",
						"aggregateOnDept, Department join(department == deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinOnDept",
						"joinOnDept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['TotalEmployeesbyDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          depname,",
						"          TotalEmp",
						"     ),",
						"     partitionBy('hash', 1)) ~> TotalEmployeebydept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnionDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ITEmployees",
								"type": "DatasetReference"
							},
							"name": "ITEmployees"
						},
						{
							"dataset": {
								"referenceName": "HREmployees",
								"type": "DatasetReference"
							},
							"name": "HREmployees"
						},
						{
							"dataset": {
								"referenceName": "PayrollEmployees",
								"type": "DatasetReference"
							},
							"name": "PayrollEmployee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "AllEmployeesSink"
						}
					],
					"transformations": [
						{
							"name": "unionALLEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ITEmployees",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> HREmployees",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> PayrollEmployee",
						"ITEmployees, HREmployees, PayrollEmployee union(byName: true)~> unionALLEmployees",
						"unionALLEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['AllEmployeesUnion.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> AllEmployeesSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnpivotDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PurchaseOrderDataSet",
								"type": "DatasetReference"
							},
							"name": "PurchaseOrder"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as string,",
						"          Vendor as string,",
						"          Apple as string,",
						"          Mango as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> PurchaseOrder",
						"PurchaseOrder unpivot(output(",
						"          Fruits as string,",
						"          Amount as string",
						"     ),",
						"     ungroupBy(PO,",
						"          Vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['unpivottedData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Validatedataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Validateschema.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/WindowDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees window(over(department),",
						"     desc(salary, true),",
						"     Denserank = denseRank()) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Windowpartitiiondata.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dafilterPayrollEmp')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "payrollEmpData"
						}
					],
					"transformations": [
						{
							"name": "filterPayrolldept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(equals(department,'3')) ~> filterPayrolldept",
						"filterPayrolldept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Payroll.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> payrollEmpData"
					]
				}
			},
			"dependsOn": []
		}
	]
}