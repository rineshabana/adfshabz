{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "shabzadfdemo"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/pipeline5')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"structure"
							],
							"storeSettings": {
								"type": "AzureBlobStorageReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Completed"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.structure",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Set variable1",
									"type": "SetVariable",
									"dependsOn": [],
									"policy": {
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"variableName": "fileName",
										"value": {
											"value": "@item().name",
											"type": "Expression"
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"variables": {
					"fileName": {
						"type": "String"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-01-18T12:18:32Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/switchActivity')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Switch1",
						"type": "Switch",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"on": {
								"value": "@pipeline().parameters.folderName",
								"type": "Expression"
							},
							"cases": [
								{
									"value": "Output1",
									"activities": [
										{
											"name": "Copy data1",
											"type": "Copy",
											"dependsOn": [],
											"policy": {
												"timeout": "0.12:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"typeProperties": {
												"source": {
													"type": "BinarySource",
													"storeSettings": {
														"type": "AzureBlobStorageReadSettings",
														"recursive": true
													},
													"formatSettings": {
														"type": "BinaryReadSettings"
													}
												},
												"sink": {
													"type": "BinarySink",
													"storeSettings": {
														"type": "AzureBlobStorageWriteSettings"
													}
												},
												"enableStaging": false
											},
											"inputs": [
												{
													"referenceName": "inputDataDataSet",
													"type": "DatasetReference",
													"parameters": {}
												}
											],
											"outputs": [
												{
													"referenceName": "OutputLocationDataSet",
													"type": "DatasetReference",
													"parameters": {
														"outputFolder": {
															"value": "@pipeline().parameters.folderName",
															"type": "Expression"
														}
													}
												}
											]
										}
									]
								},
								{
									"value": "output2",
									"activities": [
										{
											"name": "Copy data2",
											"type": "Copy",
											"dependsOn": [],
											"policy": {
												"timeout": "0.12:00:00",
												"retry": 0,
												"retryIntervalInSeconds": 30,
												"secureOutput": false,
												"secureInput": false
											},
											"userProperties": [],
											"typeProperties": {
												"source": {
													"type": "BinarySource",
													"storeSettings": {
														"type": "AzureBlobStorageReadSettings",
														"recursive": true
													},
													"formatSettings": {
														"type": "BinaryReadSettings"
													}
												},
												"sink": {
													"type": "BinarySink",
													"storeSettings": {
														"type": "AzureBlobStorageWriteSettings"
													}
												},
												"enableStaging": false
											},
											"inputs": [
												{
													"referenceName": "inputDataDataSet",
													"type": "DatasetReference",
													"parameters": {}
												}
											],
											"outputs": [
												{
													"referenceName": "Binary2",
													"type": "DatasetReference",
													"parameters": {
														"folder": {
															"value": "@pipeline().parameters.folderName",
															"type": "Expression"
														}
													}
												}
											]
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"folderName": {
						"type": "string",
						"defaultValue": "output1"
					}
				},
				"annotations": [],
				"lastPublishTime": "2024-01-05T14:39:48Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DataSetSqlTable')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "SqlServerOnPremise",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "tbl_Employees"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CacheSinkdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "maxaggregate"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 aggregate(MaxSalary = max(toInteger(salary)),",
						"     partitionBy('hash', 1)) ~> maxaggregate",
						"maxaggregate sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ExistsDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "DeptexistSink"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employee",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employee, Department exists(department == deptid,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['NotExistDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> DeptexistSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Flattendataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeesJson",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          name as string,",
						"          skills as string[],",
						"          Address as (state as string, country as string, zipcode as string),",
						"          Contact as (Phone as string, email as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments',",
						"     partitionBy('hash', 1)) ~> Employees",
						"Employees foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills,",
						"          Address,",
						"          Contact",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['FlattenData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/GroupBypowerquery')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "EmployeeDataSet",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tpartitionBy('hash', 1)) ~> EmployeeDataSet",
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared EmployeeDataSet = let AdfDoc = AzureStorage.BlobContents(\"https://storagedemoshabz.blob.core.windows.net/adfdemo/input/employee.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"EmployeeDataSet\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"department\"}, {{\"TotalEmp\", each Table.RowCount(_), Int64.Type}}) in #\"Grouped rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/LookUpDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees, Department lookup(department == deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['lookup.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/NewBranchdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregateOnDept"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees aggregate(groupBy(department),",
						"     TotalEmployees = count(empid),",
						"     partitionBy('hash', 1)) ~> aggregateOnDept",
						"Employees, Department join(department == deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"aggregateOnDept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['AggregatebyEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          department,",
						"          TotalEmployees",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          deptid,",
						"          depname",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ParameterizeMappingdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     deptName as string",
						"}",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees",
						"Employees filter(department == $deptName) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpParamData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/PivotDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Employees1DataSet",
								"type": "DatasetReference"
							},
							"name": "Employees1DataFlow"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employees1DataFlow",
						"Employees1DataFlow pivot(groupBy(department),",
						"     pivotBy(gender),",
						"     {} = count(empid),",
						"     columnNaming: 'Total_$N$VEmployees_',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['pivotdata.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Scehmadataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          salary as string,",
						"          department as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false,",
						"     preferredIntegralType: 'integer') ~> Employees",
						"Employees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['schema.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Selectdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "selectOnEmp"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees select(mapColumn(",
						"          {Emp Name} = name,",
						"          Empid = empid,",
						"          Country = country",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> selectOnEmp",
						"selectOnEmp sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SelectEmp.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Sortdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sortOnName"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees sort(asc(name, true),",
						"     caseInsensitive: true) ~> sortOnName",
						"sortOnName sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SortEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SplitDF')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "AllEmployees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "ITEmployeesSink",
							"rejectedDataLinkedService": {
								"referenceName": "LinkedService_StorageDemo",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "PayrollEmployeeSink"
						},
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "HREmployeeSink"
						}
					],
					"transformations": [
						{
							"name": "ITEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> AllEmployees",
						"AllEmployees split(equals(department,'1'),",
						"     equals(department,'2'),",
						"     equals(department,'3'),",
						"     disjoint: false) ~> ITEmployees@(ITEmployee, PayrollEmployee, HREmployee)",
						"ITEmployees@ITEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ITEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ITEmployeesSink",
						"ITEmployees@PayrollEmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['PayrollEmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PayrollEmployeeSink",
						"ITEmployees@HREmployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['HREmployee.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> HREmployeeSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Surrogatedataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "SurrogateKeyDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          department",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Surrogatedata.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/TotalEmpbyDept')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						},
						{
							"dataset": {
								"referenceName": "DeprtamentdataSet",
								"type": "DatasetReference"
							},
							"name": "Department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "TotalEmployeebydept"
						}
					],
					"transformations": [
						{
							"name": "aggregateOnDept"
						},
						{
							"name": "joinOnDept"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"source(output(",
						"          deptid as string,",
						"          depname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Department",
						"Employees aggregate(groupBy(department),",
						"     TotalEmp = count(empid)) ~> aggregateOnDept",
						"aggregateOnDept, Department join(department == deptid,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> joinOnDept",
						"joinOnDept sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['TotalEmployeesbyDept.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          depname,",
						"          TotalEmp",
						"     ),",
						"     partitionBy('hash', 1)) ~> TotalEmployeebydept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnionDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ITEmployees",
								"type": "DatasetReference"
							},
							"name": "ITEmployees"
						},
						{
							"dataset": {
								"referenceName": "HREmployees",
								"type": "DatasetReference"
							},
							"name": "HREmployees"
						},
						{
							"dataset": {
								"referenceName": "PayrollEmployees",
								"type": "DatasetReference"
							},
							"name": "PayrollEmployee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "AllEmployeesSink"
						}
					],
					"transformations": [
						{
							"name": "unionALLEmployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ITEmployees",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> HREmployees",
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> PayrollEmployee",
						"ITEmployees, HREmployees, PayrollEmployee union(byName: true)~> unionALLEmployees",
						"unionALLEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['AllEmployeesUnion.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> AllEmployeesSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnpivotDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "PurchaseOrderDataSet",
								"type": "DatasetReference"
							},
							"name": "PurchaseOrder"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as string,",
						"          Vendor as string,",
						"          Apple as string,",
						"          Mango as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> PurchaseOrder",
						"PurchaseOrder unpivot(output(",
						"          Fruits as string,",
						"          Amount as string",
						"     ),",
						"     ungroupBy(PO,",
						"          Vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['unpivottedData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Validatedataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "EmployeeDataSet",
								"type": "DatasetReference"
							},
							"name": "Employees"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "OutputdataSet",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          name as string,",
						"          salary as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     ignoreNoFilesFound: false) ~> Employees",
						"Employees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Validateschema.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}